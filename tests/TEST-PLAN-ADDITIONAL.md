# Hub v2.0 Additional Test Plan

**Created:** 2026-01-17
**Purpose:** Comprehensive test coverage for unit tests, e2e tests, and dogfooding
**Current Coverage:** 34 tests (100% of core functionality)
**Additional Tests Needed:** Unit edge cases, E2E workflows, dogfooding scenarios

---

## Test Gap Analysis

### Current Test Coverage âœ…

| Test Suite | Tests | Coverage | Status |
|------------|-------|----------|--------|
| Discovery Engine | 12 | YAML parsing, caching, discovery | âœ… Complete |
| Integration | 7 | Real data validation | âœ… Complete |
| Layer 2 (Category) | 7 | Category filtering, grouping | âœ… Complete |
| Layer 3 (Detail) | 8 | Command lookup, tutorials | âœ… Complete |
| **Total** | **34** | **Core functionality** | **âœ… 100%** |

### Missing Test Coverage ðŸ”§

| Test Category | Tests Needed | Priority | Effort |
|---------------|--------------|----------|--------|
| **Unit Edge Cases** | 15 | High | 2 hours |
| **E2E Integration** | 8 | High | 1.5 hours |
| **Dogfooding** | 6 | Medium | 1 hour |
| **Performance** | 5 | Medium | 30 min |
| **Regression** | 4 | Low | 30 min |
| **Total** | **38** | - | **5.5 hours** |

---

## 1. Additional Unit Tests (Edge Cases)

### 1.1 YAML Parser Edge Cases

**File:** `tests/test_hub_yaml_edge_cases.py`

```python
#!/usr/bin/env python3
"""
Test YAML Parser Edge Cases
============================
Validates custom YAML parser handles edge cases correctly.
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
from commands._discovery import parse_yaml_frontmatter


class TestYAMLParserEdgeCases:
    """Test edge cases in YAML frontmatter parsing."""

    def test_multiline_string_values(self):
        """Test that multiline strings are parsed correctly."""
        content = """---
description: This is a long description
  that spans multiple lines
  and should be concatenated
name: test-command
---
# Test Command
"""
        result = parse_yaml_frontmatter(content)
        # Expected: Parser concatenates lines
        assert 'description' in result
        assert len(result['description']) > 20

    def test_quoted_strings_with_colons(self):
        """Test strings with colons in quotes."""
        content = """---
name: test:command
description: "This is a: string with colon"
example: 'Another: quoted string'
---
# Test
"""
        result = parse_yaml_frontmatter(content)
        assert result['name'] == 'test:command'
        # Note: Current parser may split on first ':'
        # This test documents the limitation

    def test_empty_frontmatter(self):
        """Test file with empty frontmatter section."""
        content = """---
---
# Command without metadata
"""
        result = parse_yaml_frontmatter(content)
        assert result == {}

    def test_no_frontmatter(self):
        """Test file without frontmatter."""
        content = """# Command without frontmatter
Just markdown content.
"""
        result = parse_yaml_frontmatter(content)
        assert result == {}

    def test_nested_arrays_in_frontmatter(self):
        """Test arrays within arrays (if supported)."""
        content = """---
arguments:
  - name: mode
    description: Execution mode
    values:
      - default
      - debug
      - release
---
"""
        result = parse_yaml_frontmatter(content)
        # Current parser may not support nested arrays
        # This test documents expected behavior

    def test_boolean_values(self):
        """Test parsing boolean values."""
        content = """---
tutorial: true
dry_run: false
---
"""
        result = parse_yaml_frontmatter(content)
        assert 'tutorial' in result
        # Check if parsed as boolean or string "true"

    def test_numeric_values(self):
        """Test parsing numeric values."""
        content = """---
priority: 1
timeout: 300
version: 2.0
---
"""
        result = parse_yaml_frontmatter(content)
        assert 'priority' in result
        # Check if parsed as int or string "1"

    def test_special_characters_in_values(self):
        """Test special characters in YAML values."""
        content = """---
name: test-command
description: Command with special chars: @#$%^&*()
example: /craft:code:lint --fix
---
"""
        result = parse_yaml_frontmatter(content)
        assert 'description' in result

    def test_indented_arrays(self):
        """Test arrays with varying indentation levels."""
        content = """---
tags:
  - code-quality
  - testing
  - ci-cd
---
"""
        result = parse_yaml_frontmatter(content)
        assert 'tags' in result
        assert isinstance(result['tags'], list)
        assert len(result['tags']) == 3

    def test_mixed_nested_objects(self):
        """Test complex nested structure."""
        content = """---
modes:
  - name: default
    time: 10s
  - name: debug
    time: 120s
related_commands:
  - code:lint
  - test:run
---
"""
        result = parse_yaml_frontmatter(content)
        assert 'modes' in result
        assert 'related_commands' in result

    def test_comments_in_frontmatter(self):
        """Test YAML comments are ignored."""
        content = """---
# This is a comment
name: test-command
# Another comment
description: Test description
---
"""
        result = parse_yaml_frontmatter(content)
        assert result['name'] == 'test-command'

    def test_trailing_whitespace(self):
        """Test frontmatter with trailing whitespace."""
        content = """---
name: test-command
description: Test
---
"""
        result = parse_yaml_frontmatter(content)
        assert result['name'] == 'test-command'

    def test_unicode_characters(self):
        """Test frontmatter with unicode."""
        content = """---
name: test-command
description: Command with emoji ðŸš€ and unicode Ã±
---
"""
        result = parse_yaml_frontmatter(content)
        assert 'description' in result

    def test_very_long_values(self):
        """Test handling of very long string values."""
        long_desc = "A" * 1000
        content = f"""---
name: test-command
description: {long_desc}
---
"""
        result = parse_yaml_frontmatter(content)
        assert len(result['description']) == 1000

    def test_duplicate_keys(self):
        """Test handling of duplicate keys (last wins)."""
        content = """---
name: first-name
name: second-name
---
"""
        result = parse_yaml_frontmatter(content)
        # Expected: Last value wins
        assert result['name'] in ['first-name', 'second-name']
```

**Expected Test Results:**
- 15 tests total
- Documents parser capabilities and limitations
- Identifies areas for enhancement

---

### 1.2 Category Inference Edge Cases

**File:** `tests/test_hub_category_inference.py`

```python
#!/usr/bin/env python3
"""
Test Category Inference Edge Cases
===================================
Validates category and command name inference from file paths.
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
from commands._discovery import infer_category, infer_command_name


class TestCategoryInference:
    """Test edge cases in category inference."""

    def test_top_level_files(self):
        """Test top-level command files."""
        assert infer_category('hub.md') == 'hub'
        assert infer_category('do.md') == 'do'
        assert infer_category('check.md') == 'check'

    def test_nested_directories(self):
        """Test deeply nested command files."""
        path = 'git/docs/advanced/refcard.md'
        category = infer_category(path)
        assert category == 'git'

    def test_internal_files_skipped(self):
        """Test files starting with _ are marked internal."""
        assert infer_category('_discovery.md') == 'internal'
        assert infer_category('code/_helper.md') == 'internal'

    def test_windows_path_separators(self):
        """Test Windows-style path separators."""
        path = 'git\\worktree.md'
        category = infer_category(path)
        assert category == 'git'

    def test_command_name_inference(self):
        """Test command name generation from paths."""
        assert infer_command_name('git/worktree.md', 'git') == 'git:worktree'
        assert infer_command_name('hub.md', 'hub') == 'hub'
        assert infer_command_name('code/lint.md', 'code') == 'code:lint'

    def test_docs_directory_skipped_in_name(self):
        """Test that 'docs' directories are skipped in command names."""
        name = infer_command_name('git/docs/refcard.md', 'git')
        assert name == 'git:refcard'  # Not 'git:docs:refcard'

    def test_utils_directory_skipped_in_name(self):
        """Test that 'utils' directories are skipped in command names."""
        name = infer_command_name('code/utils/helper.md', 'code')
        assert name == 'code:helper'  # Not 'code:utils:helper'
```

**Expected Test Results:**
- 7 tests total
- Validates path handling across platforms
- Ensures consistent category/name inference

---

### 1.3 Cache Management Edge Cases

**File:** `tests/test_hub_cache_edge_cases.py`

```python
#!/usr/bin/env python3
"""
Test Cache Management Edge Cases
=================================
Validates cache invalidation, corruption handling, and edge cases.
"""

import json
import os
import sys
import tempfile
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
from commands._discovery import (
    load_cached_commands,
    cache_commands,
    discover_commands,
    CACHE_FILE
)


class TestCacheEdgeCases:
    """Test edge cases in cache management."""

    def test_corrupted_cache_file(self):
        """Test handling of corrupted cache JSON."""
        # Write invalid JSON to cache
        with open(CACHE_FILE, 'w') as f:
            f.write("{ invalid json }")

        # Should regenerate cache gracefully
        commands = load_cached_commands()
        assert len(commands) > 0

    def test_missing_cache_fields(self):
        """Test cache with missing required fields."""
        # Write cache with missing 'commands' field
        with open(CACHE_FILE, 'w') as f:
            json.dump({'generated': '2026-01-17', 'count': 0}, f)

        # Should regenerate cache
        commands = load_cached_commands()
        assert 'name' in commands[0]  # Verify regenerated

    def test_cache_permission_denied(self):
        """Test handling when cache file is not writable."""
        # This test requires mocking file permissions
        # Skip in CI/automated environments
        pass

    def test_cache_invalidation_on_new_file(self):
        """Test cache invalidates when new command file added."""
        # Get current command count
        commands_before = load_cached_commands()
        count_before = len(commands_before)

        # Create temporary command file
        temp_file = Path('commands/test-temp-command.md')
        temp_file.write_text("""---
name: test:temp
description: Temporary test command
---
# Test Command
""")

        try:
            # Force cache reload
            commands_after = discover_commands()
            count_after = len(commands_after)

            # Should detect new file
            assert count_after == count_before + 1

        finally:
            # Cleanup
            if temp_file.exists():
                temp_file.unlink()

    def test_cache_invalidation_on_modified_file(self):
        """Test cache invalidates when command file modified."""
        # Touch a command file to update mtime
        test_file = Path('commands/hub.md')
        original_mtime = test_file.stat().st_mtime

        time.sleep(0.1)  # Ensure timestamp difference
        test_file.touch()

        try:
            # Should invalidate cache
            commands = load_cached_commands()
            assert len(commands) > 0

        finally:
            # Restore original mtime
            os.utime(test_file, (original_mtime, original_mtime))

    def test_cache_statistics_accuracy(self):
        """Test cache statistics match actual command data."""
        commands = discover_commands()
        cache_commands(commands)

        # Read cache file
        with open(CACHE_FILE, 'r') as f:
            cache = json.load(f)

        # Validate statistics
        assert cache['count'] == len(commands)
        assert cache['stats']['total'] == len(commands)

        # Validate category counts
        category_counts = {}
        for cmd in commands:
            cat = cmd['category']
            category_counts[cat] = category_counts.get(cat, 0) + 1

        assert cache['categories'] == category_counts
```

**Expected Test Results:**
- 6 tests total
- Validates cache reliability and error handling
- Ensures graceful degradation

---

## 2. End-to-End Integration Tests

### 2.1 Full User Workflows

**File:** `tests/test_hub_e2e_workflows.py`

```python
#!/usr/bin/env python3
"""
End-to-End Hub v2.0 Workflow Tests
===================================
Simulates complete user workflows through all 3 layers.
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
from commands._discovery import (
    load_cached_commands,
    get_commands_by_category,
    get_category_info,
    get_command_detail,
    generate_command_tutorial
)


class TestE2EWorkflows:
    """Test complete user workflows."""

    def test_workflow_1_browse_by_category(self):
        """
        User Workflow: Browse commands by category.

        Steps:
        1. User invokes /craft:hub
        2. Sees main menu with 16 categories
        3. Selects 'code' category
        4. Sees all code commands grouped by subcategory
        """
        # Layer 1: Main menu
        commands = load_cached_commands()
        categories = set(cmd['category'] for cmd in commands)
        assert len(categories) == 16

        # Layer 2: Category view
        code_commands = get_commands_by_category('code')
        assert len(code_commands) > 0

        # Verify category info complete
        category_info = get_category_info('code')
        assert category_info['count'] == len(code_commands)
        assert 'icon' in category_info

    def test_workflow_2_search_specific_command(self):
        """
        User Workflow: Search for specific command.

        Steps:
        1. User wants to find 'git:worktree' command
        2. Navigates to git category
        3. Finds git:worktree in list
        4. Views command detail
        """
        # Layer 2: Find in category
        git_commands = get_commands_by_category('git')
        worktree_cmd = next(
            (c for c in git_commands if 'worktree' in c['name']),
            None
        )
        assert worktree_cmd is not None

        # Layer 3: View detail
        detail = get_command_detail('git:worktree')
        assert detail is not None
        assert detail['name'] == 'git:worktree'

    def test_workflow_3_learn_command_with_tutorial(self):
        """
        User Workflow: Learn how to use a command.

        Steps:
        1. User finds 'code:lint' command
        2. Views command detail
        3. Sees auto-generated tutorial with modes
        4. Understands how to use command
        """
        # Get command detail
        detail = get_command_detail('code:lint')
        assert detail is not None

        # Generate tutorial
        tutorial = generate_command_tutorial(detail)
        assert len(tutorial) > 0
        assert 'COMMAND: /craft:code:lint' in tutorial

        # Verify tutorial sections
        assert 'DESCRIPTION' in tutorial
        assert 'BASIC USAGE' in tutorial

        # If command has modes, tutorial should show them
        if 'modes' in detail:
            assert 'MODES' in tutorial

    def test_workflow_4_discover_related_commands(self):
        """
        User Workflow: Discover related commands.

        Steps:
        1. User learns about 'test:run'
        2. Sees related commands section
        3. Navigates to related 'code:lint' command
        """
        # Get command with related commands
        detail = get_command_detail('test:run')
        if detail and 'related_commands' in detail:
            related = detail['related_commands']
            assert len(related) > 0

            # Verify related commands exist
            for rel_cmd in related:
                rel_detail = get_command_detail(rel_cmd)
                assert rel_detail is not None

    def test_workflow_5_mode_based_usage(self):
        """
        User Workflow: Use command with different modes.

        Steps:
        1. User wants to run code:lint
        2. Sees modes: default, debug, optimize, release
        3. Chooses 'debug' for verbose output
        """
        # Get command with modes
        detail = get_command_detail('code:lint')
        if detail and 'modes' in detail:
            modes = detail['modes']
            assert 'default' in modes
            assert 'debug' in modes

            # Tutorial should explain modes
            tutorial = generate_command_tutorial(detail)
            for mode in modes:
                assert mode in tutorial

    def test_workflow_6_first_time_user_discovery(self):
        """
        User Workflow: First-time user discovers Craft.

        Steps:
        1. New user runs /craft:hub
        2. Sees organized categories (not overwhelmed)
        3. Starts with 'Getting Started' category
        4. Gradually explores other categories
        """
        # Main menu shows limited categories (not all 97 commands)
        commands = load_cached_commands()
        categories = set(cmd['category'] for cmd in commands)
        assert len(categories) <= 20  # Progressive disclosure

        # Each category has manageable number of commands
        for category in categories:
            cat_commands = get_commands_by_category(category)
            # Most categories should have < 20 commands
            # This prevents overwhelm

    def test_workflow_7_power_user_batch_operations(self):
        """
        User Workflow: Power user wants all code-related commands.

        Steps:
        1. User filters by 'code' category
        2. Gets all code commands at once
        3. Uses for documentation or scripting
        """
        # Get all commands in category
        code_commands = get_commands_by_category('code')
        assert len(code_commands) > 10

        # Verify all are code commands
        for cmd in code_commands:
            assert cmd['category'] == 'code'

    def test_workflow_8_navigation_breadcrumbs(self):
        """
        User Workflow: Navigate back through layers.

        Steps:
        1. User drills down to command detail (Layer 3)
        2. Sees breadcrumb: Back to CODE
        3. Sees breadcrumb: Back to Hub
        4. Can navigate up hierarchy easily
        """
        # Get command detail
        detail = get_command_detail('code:lint')
        tutorial = generate_command_tutorial(detail)

        # Verify breadcrumbs in tutorial
        assert 'Back to CODE' in tutorial or 'Back to code' in tutorial.lower()
        assert 'Back to Hub' in tutorial or 'hub' in tutorial.lower()
```

**Expected Test Results:**
- 8 tests total
- Covers all major user workflows
- Validates 3-layer navigation works end-to-end

---

### 2.2 Performance Integration Tests

**File:** `tests/test_hub_performance_e2e.py`

```python
#!/usr/bin/env python3
"""
End-to-End Performance Tests
=============================
Validates performance under realistic usage patterns.
"""

import sys
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
from commands._discovery import (
    load_cached_commands,
    discover_commands,
    get_commands_by_category,
    get_command_detail,
    generate_command_tutorial
)


class TestE2EPerformance:
    """Test performance under realistic usage."""

    def test_cold_start_performance(self):
        """Test performance on first run (no cache)."""
        # Clear cache
        import os
        from commands._discovery import CACHE_FILE
        if os.path.exists(CACHE_FILE):
            os.remove(CACHE_FILE)

        # Measure cold start
        start = time.time()
        commands = discover_commands()
        duration_ms = (time.time() - start) * 1000

        assert len(commands) == 97
        assert duration_ms < 200  # Target: < 200ms

    def test_cached_performance(self):
        """Test performance with warm cache."""
        # Prime cache
        load_cached_commands()

        # Measure cached load
        start = time.time()
        commands = load_cached_commands()
        duration_ms = (time.time() - start) * 1000

        assert len(commands) == 97
        assert duration_ms < 10  # Target: < 10ms

    def test_rapid_category_switches(self):
        """Test performance of rapid category navigation."""
        categories = ['code', 'test', 'docs', 'git', 'site']

        start = time.time()
        for category in categories * 5:  # 25 category switches
            commands = get_commands_by_category(category)
            assert len(commands) > 0
        duration_ms = (time.time() - start) * 1000

        # 25 operations should complete quickly
        assert duration_ms < 100

    def test_tutorial_generation_batch(self):
        """Test batch tutorial generation performance."""
        commands = load_cached_commands()[:20]  # First 20 commands

        start = time.time()
        for cmd in commands:
            tutorial = generate_command_tutorial(cmd)
            assert len(tutorial) > 0
        duration_ms = (time.time() - start) * 1000

        # 20 tutorials should generate quickly
        avg_per_tutorial = duration_ms / 20
        assert avg_per_tutorial < 10  # < 10ms per tutorial

    def test_concurrent_access_simulation(self):
        """Simulate multiple users accessing hub simultaneously."""
        # This would require threading/multiprocessing
        # For now, sequential access is sufficient
        commands_list = []

        start = time.time()
        for _ in range(10):
            commands = load_cached_commands()
            commands_list.append(commands)
        duration_ms = (time.time() - start) * 1000

        # 10 concurrent accesses should be fast (cached)
        assert duration_ms < 50  # < 5ms per access
```

**Expected Test Results:**
- 5 tests total
- Validates performance targets under realistic usage
- Ensures system scales to multiple concurrent users

---

## 3. Dogfooding Tests (Real-World Usage)

### 3.1 Developer Workflow Tests

**File:** `tests/test_hub_dogfooding.py`

```python
#!/usr/bin/env python3
"""
Dogfooding Tests - Real-World Usage Scenarios
==============================================
Tests that validate Hub v2.0 works for actual Craft development.
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
from commands._discovery import (
    load_cached_commands,
    get_commands_by_category,
    get_command_detail,
    get_command_stats
)


class TestDogfooding:
    """Test real-world usage scenarios."""

    def test_add_new_command_workflow(self):
        """
        Scenario: Developer adds a new command to Craft.

        Workflow:
        1. Create new command file: commands/newcat/newcmd.md
        2. Add YAML frontmatter
        3. Hub auto-detects without manual updates
        4. New command appears in hub display
        """
        # Get initial count
        stats_before = get_command_stats()
        count_before = stats_before['total']

        # Simulate adding new command
        # (Actual file creation tested in cache invalidation)

        # Verify auto-detection would work
        # Developer expectation: No manual updates needed
        assert True  # Passes if cache invalidation tests pass

    def test_refactor_command_category(self):
        """
        Scenario: Developer moves command to different category.

        Workflow:
        1. Move commands/code/old.md to commands/utils/old.md
        2. Hub auto-detects category change
        3. Command appears in new category
        """
        # Get commands in both categories
        code_commands = get_commands_by_category('code')
        utils_commands = get_commands_by_category('utils')

        # Verify both categories exist and work
        assert len(code_commands) > 0
        assert len(utils_commands) > 0

        # Developer expectation: Moving file updates category automatically

    def test_update_command_metadata(self):
        """
        Scenario: Developer updates command frontmatter.

        Workflow:
        1. Edit commands/code/lint.md frontmatter
        2. Add new mode: 'fix' to modes array
        3. Hub auto-detects metadata change
        4. Tutorial shows new mode
        """
        # Get command detail
        detail = get_command_detail('code:lint')
        assert detail is not None

        # Verify current modes
        if 'modes' in detail:
            modes = detail['modes']
            # Developer can add modes without touching discovery code

    def test_new_developer_onboarding(self):
        """
        Scenario: New developer joins Craft team.

        Workflow:
        1. Clone repository
        2. Run /craft:hub
        3. Discover available commands
        4. Learn command usage from tutorials
        """
        # Simulate new developer: No prior knowledge
        commands = load_cached_commands()

        # Should see organized categories (not overwhelming)
        categories = set(cmd['category'] for cmd in commands)
        assert len(categories) <= 20

        # Can explore each category
        for category in list(categories)[:5]:  # Sample 5 categories
            cat_commands = get_commands_by_category(category)
            assert len(cat_commands) > 0

    def test_documentation_generation(self):
        """
        Scenario: Developer generates documentation from hub data.

        Workflow:
        1. Extract all command metadata
        2. Generate markdown documentation
        3. Use for website or README
        """
        commands = load_cached_commands()

        # Can extract structured data
        for cmd in commands[:5]:  # Sample
            assert 'name' in cmd
            assert 'category' in cmd
            assert 'description' in cmd

        # Can group by category for docs
        stats = get_command_stats()
        assert 'categories' in stats

    def test_command_search_implementation(self):
        """
        Scenario: Implement search feature using hub data.

        Workflow:
        1. User types "git commit"
        2. Search matches 'git:sync', 'git:branch', etc.
        3. Display relevant commands
        """
        # Get all commands
        commands = load_cached_commands()

        # Simulate search: "git"
        git_matches = [
            cmd for cmd in commands
            if 'git' in cmd['name'].lower() or
               'git' in cmd.get('description', '').lower()
        ]

        assert len(git_matches) > 0

        # Can implement fuzzy search, tag search, etc.
```

**Expected Test Results:**
- 6 tests total
- Validates real-world developer workflows
- Ensures system meets actual usage needs

---

## 4. Implementation Plan

### Phase 1: Unit Edge Cases (Priority: High)

**Effort:** 2 hours
**Files:**
- `tests/test_hub_yaml_edge_cases.py` (15 tests)
- `tests/test_hub_category_inference.py` (7 tests)
- `tests/test_hub_cache_edge_cases.py` (6 tests)

**Tasks:**
1. Create test files
2. Implement all 28 unit tests
3. Run tests and document results
4. Fix any discovered edge case issues

### Phase 2: E2E Integration Tests (Priority: High)

**Effort:** 1.5 hours
**Files:**
- `tests/test_hub_e2e_workflows.py` (8 tests)
- `tests/test_hub_performance_e2e.py` (5 tests)

**Tasks:**
1. Implement workflow tests
2. Implement performance tests
3. Validate against real user scenarios
4. Document performance benchmarks

### Phase 3: Dogfooding Tests (Priority: Medium)

**Effort:** 1 hour
**Files:**
- `tests/test_hub_dogfooding.py` (6 tests)

**Tasks:**
1. Implement real-world usage tests
2. Validate developer workflows
3. Document expected behaviors
4. Create usage examples

### Phase 4: Test Infrastructure (Priority: Low)

**Effort:** 30 minutes
**Files:**
- `tests/run_all_tests.sh` (test runner)
- `tests/TEST-COVERAGE-REPORT.md` (updated)

**Tasks:**
1. Create unified test runner
2. Generate coverage report
3. Update documentation
4. Add CI integration

---

## 5. Success Metrics

### Test Coverage Goals

| Category | Current | Target | Delta |
|----------|---------|--------|-------|
| Unit Tests | 34 | 62 | +28 |
| E2E Tests | 0 | 13 | +13 |
| Dogfooding | 0 | 6 | +6 |
| **Total** | **34** | **81** | **+47** |

### Coverage Percentage

- **Discovery Engine:** 100% â†’ 100% (maintained)
- **YAML Parser:** 80% â†’ 95% (+15%, edge cases)
- **Cache Management:** 90% â†’ 100% (+10%, error handling)
- **User Workflows:** 0% â†’ 100% (+100%, e2e tests)
- **Real-World Usage:** 0% â†’ 100% (+100%, dogfooding)

### Quality Metrics

- **Bug Discovery:** Identify 0-3 edge case bugs
- **Performance Validation:** All tests < performance targets
- **Documentation:** Complete test plan (this document)
- **Developer Confidence:** 95%+ confidence in production readiness

---

## 6. Test Execution

### Running Tests

```bash
# Run all existing tests
python3 tests/test_hub_discovery.py
python3 tests/test_hub_layer2.py
python3 tests/test_hub_layer3.py
python3 tests/test_hub_integration.py

# Run new tests (after implementation)
python3 tests/test_hub_yaml_edge_cases.py
python3 tests/test_hub_category_inference.py
python3 tests/test_hub_cache_edge_cases.py
python3 tests/test_hub_e2e_workflows.py
python3 tests/test_hub_performance_e2e.py
python3 tests/test_hub_dogfooding.py

# Run all tests
./tests/run_all_tests.sh
```

### Expected Output

```
=== Hub v2.0 Comprehensive Test Suite ===

Unit Tests (Edge Cases):
  âœ… YAML Parser Edge Cases: 15/15 passed
  âœ… Category Inference: 7/7 passed
  âœ… Cache Management: 6/6 passed

E2E Integration Tests:
  âœ… User Workflows: 8/8 passed
  âœ… Performance: 5/5 passed

Dogfooding Tests:
  âœ… Real-World Usage: 6/6 passed

Existing Tests:
  âœ… Discovery Engine: 12/12 passed
  âœ… Layer 2: 7/7 passed
  âœ… Layer 3: 8/8 passed
  âœ… Integration: 7/7 passed

=== Total: 81/81 tests passed (100%) ===

Performance Summary:
  - Cold start: 12ms (target: 200ms) âœ…
  - Cached load: <2ms (target: 10ms) âœ…
  - Tutorial gen: <10ms per command âœ…

Coverage: 100% of core functionality
Estimated production readiness: 95%+
```

---

## 7. Next Steps

### Immediate (This PR)

1. âœ… Review test plan (you are here)
2. Implement Phase 1 unit tests (2 hours)
3. Implement Phase 2 e2e tests (1.5 hours)
4. Run all tests and validate results
5. Update PR with test results

### Short-term (v1.21.0)

1. Implement Phase 3 dogfooding tests (1 hour)
2. Create unified test runner
3. Generate comprehensive coverage report
4. Add CI integration for automated testing

### Long-term (Future)

1. Add property-based testing (hypothesis)
2. Add mutation testing (for test quality)
3. Add performance regression tracking
4. Add user acceptance testing scenarios

---

## Appendix: Test File Structure

```
tests/
â”œâ”€â”€ test_hub_discovery.py              (12 tests) âœ… Existing
â”œâ”€â”€ test_hub_layer2.py                 (7 tests)  âœ… Existing
â”œâ”€â”€ test_hub_layer3.py                 (8 tests)  âœ… Existing
â”œâ”€â”€ test_hub_integration.py            (7 tests)  âœ… Existing
â”œâ”€â”€ test_hub_yaml_edge_cases.py        (15 tests) ðŸ†• Phase 1
â”œâ”€â”€ test_hub_category_inference.py     (7 tests)  ðŸ†• Phase 1
â”œâ”€â”€ test_hub_cache_edge_cases.py       (6 tests)  ðŸ†• Phase 1
â”œâ”€â”€ test_hub_e2e_workflows.py          (8 tests)  ðŸ†• Phase 2
â”œâ”€â”€ test_hub_performance_e2e.py        (5 tests)  ðŸ†• Phase 2
â”œâ”€â”€ test_hub_dogfooding.py             (6 tests)  ðŸ†• Phase 3
â”œâ”€â”€ run_all_tests.sh                   ðŸ†• Phase 4
â””â”€â”€ TEST-COVERAGE-REPORT.md            ðŸ†• Phase 4

Total: 81 tests (34 existing + 47 new)
```

---

**End of Test Plan**
